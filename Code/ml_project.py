# -*- coding: utf-8 -*-
"""ML Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VDLf0rIw1SPey43g1ARrbbuWusvJ0L8F

# Creating/Plotting Data
"""

import math
import numpy as np
import matplotlib.pyplot as plt


num_trials = 1000
amplitude_ranges = []
for i in range(num_trials):
  amplitude_ranges.append(np.random.randint(1, 10))

phase_ranges= []
for i in range(num_trials):
  phase_ranges.append(np.pi/180*np.random.randint(0, 360))

signals = []

for i in range(num_trials):
  f = 5 # frequency of the sine wave we want to construct (Hz)
  sampling_rate = 200 # Number of samples per second, rate of the waveform 'measured', number of points seen (reaslitc component)
  end_time = 1 # Duration of the wave in seconds
  time = np.linspace(0, end_time, int(end_time * sampling_rate), endpoint=False) # Array of time values from 0 to duration time
  time.tolist()
  sine_wave = amplitude_ranges[i] * np.sin(2 * np.pi * f * time + phase_ranges[1]) # Calculate the sine wave values for each time value A*sin(wt +phi), w = 2pif
  sine_wave.tolist()
  signals.append(sine_wave)

signals = np.array(signals)
plt.plot(time,sine_wave) #marker = "o"
plt.xlabel('Time')
plt.ylabel('Output')
print(signals.shape)
#print(signals)
type(signals)

"""# Preprocessing Original Data for CNN"""

from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical


X_train, X_test = train_test_split(signals, test_size=0.3, random_state=123) # 70, 30 split

print(X_train.shape)
print(X_test.shape)
X_train = X_train.reshape(700, 200, 1)
X_test = X_test.reshape(300, 200, 1)
print(X_train.shape)
print(X_test.shape)

"""# Adding White Noise"""

import tensorflow as tf

noise_factor_ranges = []
mu = 0 # mean
sigma2_ranges = [] # standard deviation (variance is the square of s.d)
for i in range(len(X_train)):
  sigma2_ranges.append((np.var(X_train[i])*0.1)**2)
  noise_factor_ranges.append(np.random.randint(1,5)/10)
noise_factor_ranges = np.array(noise_factor_ranges)
sigma2_ranges = np.array(sigma2_ranges)
print(noise_factor_ranges.shape)

x_train_noisy = np.empty([700, 200, 1])
for i in range(len(X_train)):
  x_train_noisy[i] = (X_train[i] + noise_factor_ranges[i] * np.random.normal(mu, sigma2_ranges[i], size=(X_train[i].shape)))
x_train_noisy = np.array(x_train_noisy)
print(x_train_noisy.shape)




noise_factor_ranges1 = []
sigma2_ranges1 = []

for i in range(len(X_test)):
  sigma2_ranges1.append((np.var(X_test[i])*0.1)**2)
  noise_factor_ranges1.append(np.random.randint(1,5)/10)
noise_factor_ranges1 = np.array(noise_factor_ranges1)
sigma2_ranges1 = np.array(sigma2_ranges1)
print(noise_factor_ranges1.shape)

x_test_noisy = np.empty([300, 200, 1])
for i in range(len(X_test)):
  x_test_noisy[i] = (X_test[i] + noise_factor_ranges1[i] * np.random.normal(mu, sigma2_ranges1[i], size=(X_test[i].shape)))
x_test_noisy = np.array(x_test_noisy)
print(x_test_noisy.shape)



plt.plot(time, x_train_noisy[699])
plt.xlabel('Time')
plt.ylabel('Output')

type(x_train_noisy)

x_train = X_train.astype('float32')/255.
x_test = X_test.astype('float32')/255.


x_train_noisy = x_train_noisy.astype('float32')/255.
x_test_noisy = x_test_noisy.astype('float32')/255.

print(x_train_noisy.shape)
print(x_test_noisy.shape)

"""# Creating Autoencoder"""

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.model_selection import train_test_split
from tensorflow.keras import layers, losses
from tensorflow.keras.models import Model

class Denoise(Model):
  def __init__(self):
    super(Denoise, self).__init__()
    self.encoder = tf.keras.Sequential([
      layers.Input(shape=(200,1)),
      layers.Conv1D(16, 3, activation='relu', padding='same'),
      layers.Conv1D(8, 3, activation='relu', padding='same')])

    self.decoder = tf.keras.Sequential([
      layers.Conv1DTranspose(8, kernel_size=3, activation='relu', padding='same'),
      layers.Conv1DTranspose(16, kernel_size=3, activation='relu', padding='same'),
      layers.Conv1D(1, kernel_size=3, activation='sigmoid', padding='same')])

  def call(self, x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

autoencoder = Denoise()

autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())
history = autoencoder.fit(x_train_noisy, X_train,
                epochs=5,
                shuffle=True,
                validation_data=(x_test_noisy, X_test))

"""# Plotting Accuracy (not useful)"""

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

"""# Plotting Loss"""

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

"""# Plotting Denoised Signal"""

encoded_signals = autoencoder.encoder(x_test_noisy).numpy()
decoded_signals = autoencoder.decoder(encoded_signals).numpy()

print(decoded_signals.shape)

n = 10
plt.figure(figsize=(20, 4))
for i in range(n):

    # display original


    ax = plt.subplot(3, n, i + 1)
    plt.title("original")
    plt.plot(time, x_train[i])
    plt.xlabel('Time')
    plt.ylabel('Output')
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display original + noise

    bx = plt.subplot(3, n, i + n + 1)
    plt.title("original + noise")
    plt.plot(time, x_train_noisy[i])
    plt.xlabel('Time')
    plt.ylabel('Output')
    bx.get_xaxis().set_visible(False)
    bx.get_yaxis().set_visible(False)

    # display reconstruction
    cx = plt.subplot(3, n, i + n*2 + 1)
    plt.title("Denoised")
    plt.plot(time, decoded_signals[i])
    plt.xlabel('Time')
    plt.ylabel('Output')
    cx.get_xaxis().set_visible(False)
    cx.get_yaxis().set_visible(False)
plt.show()